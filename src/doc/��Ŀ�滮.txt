#=========================2012-10-9======================================
1.扫描未被注册的域名
2.可以配置的事项如下：------（搞定）
2-1.使用的线程数------（搞定）
2-2.域名的字符选择列表-------（搞定）
2-3.域名的字符长度范围------（搞定）
2-4.域名的起始扫描点，优先级大于2-3-----（搞定）
2-5.域名的机构类型--------（搞定）
2-6.线程异常时休眠时间-------（搞定）
3.发生了异常，应该能记录下异常数据，异常点
4.能查询当前扫描点
5.扫描应该是循环的，能查询当前是第几次循环
6.应该记录下域名被扫描过的次数
7.发生了异常，可能是偶然性异常（极少发生），也可能是网络原因，api查询提供商原因。
偶然性异常应该是记录下情况然后继续执行，其余原因应该程序应该能自动休眠一段时间。
8.数据库必须字段如下设计：
8-1.域名、机构名、扫描次数，最后扫描时间，注册日期，到期日期，估算分值，是否单词
8-2.扫描到一个新被注册的域名，将其从未注册表中移除到新注册表，记录下时间，可以辅助分析域名选择的趋势
9.程序强行中断后，有办法恢复之前的扫描点
10.提供一个简单web界面查询未注册域名和新注册域名
11.需要的资源
11-1.托管的数据库服务器
11-2.托管的web服务器
11-3.托管的vps，以便运行扫描程序

补充的知识
1.域名价值分析，投资分析，投资历史，现有类似网站
2.爬虫技术的其他商业价值挖掘

其他:
1.字符服务类应该能提供更强大的功能，发生异常时留住当前字符，动态设置字符开始值、结束值、最长最短，而不完全依赖配置文件。



#=========================2012-9-28======================================
1.扫描未被注册的域名
2.可以配置的事项如下：------（搞定）
2-1.使用的线程数------（搞定）
2-2.域名的字符选择列表-------（搞定）
2-3.域名的字符长度范围------（搞定）
2-4.域名的起始扫描点，优先级大于2-3-----（搞定）
2-5.域名的机构类型--------（搞定）
2-6.线程异常时休眠时间-------（搞定）
3.发生了异常，应该能记录下异常数据，异常点
4.能查询当前扫描点
5.扫描应该是循环的，能查询当前是第几次循环
6.应该记录下域名被扫描过的次数
7.发生了异常，可能是偶然性异常（极少发生），也可能是网络原因，api查询提供商原因。
偶然性异常应该是记录下情况然后继续执行，其余原因应该程序应该能自动休眠一段时间。
8.数据库必须字段如下设计：
8-1.域名、机构名、扫描次数，最后扫描时间，注册日期，到期日期，估算分值，是否单词
8-2.扫描到一个新被注册的域名，将其从未注册表中移除到新注册表，记录下时间，可以辅助分析域名选择的趋势
9.程序强行中断后，有办法恢复之前的扫描点
10.提供一个简单web界面查询未注册域名和新注册域名
11.需要的资源
11-1.托管的数据库服务器
11-2.托管的web服务器
11-3.托管的vps，以便运行扫描程序

补充的知识
1.域名价值分析，投资分析，投资历史，现有类似网站
2.爬虫技术的其他商业价值挖掘

#=========================2012-9-27======================================
1.扫描未被注册的域名
2.可以配置的事项如下：
2-1.使用的线程数
2-2.域名的字符选择列表
2-3.域名的字符长度范围
2-4.域名的起始扫描点，优先级大于2-3
2-5.域名的机构类型
2-6.线程异常时休眠时间
3.发生了异常，应该能记录下异常数据，异常点
4.能查询当前扫描点
5.扫描应该是循环的，能查询当前是第几次循环
6.应该记录下域名被扫描过的次数
7.发生了异常，可能是偶然性异常（极少发生），也可能是网络原因，api查询提供商原因。
偶然性异常应该是记录下情况然后继续执行，其余原因应该程序应该能自动休眠一段时间。
8.数据库必须字段如下设计：
8-1.域名、机构名、扫描次数，最后扫描时间，注册日期，到期日期，估算分值，是否单词
8-2.扫描到一个新被注册的域名，将其从未注册表中移除到新注册表，记录下时间，可以辅助分析域名选择的趋势
9.程序强行中断后，有办法恢复之前的扫描点
10.提供一个简单web界面查询未注册域名和新注册域名
11.需要的资源
11-1.托管的数据库服务器
11-2.托管的web服务器
11-3.托管的vps，以便运行扫描程序

补充的知识
1.域名价值分析，投资分析，投资历史，现有类似网站
2.爬虫技术的其他商业价值挖掘